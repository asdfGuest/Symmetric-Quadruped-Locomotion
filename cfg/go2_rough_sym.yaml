
train:
  gym_kwargs:
    id: Go2-Rough-Sym-Train

  load_path: None
  save_path: models/go2_rough_sym_model.pt

  trainer_kwargs:
    timesteps: 100000
    headless: True
    disable_progressbar: False
    close_environment_at_exit: False
    environment_info: info


run:
  gym_kwargs:
    id: Go2-Rough-Sym-Play
  load_path: runs\go2_rough_sym\24-12-30_09-10-33-055455_PPO\checkpoints\agent_75000.pt #models/go2_rough_sym_model.pt


policy_cls: MlpPolicy
policy_kwargs:
  observation_space: obs_space
  action_space: act_space
  device: device
  min_std: 0.1
  max_std: 1.5
  init_std: 1.0
  net_arch: [512, 256, 128]
  activ_fn: ELU

value_cls: MlpValue
value_kwargs:
  observation_space: obs_space
  device: device
  net_arch: [512, 256, 128]
  activ_fn: ELU


ppo:
  rollouts: 24
  learning_epochs: 5
  mini_batches: 4

  discount_factor: 0.99
  lambda: 0.95

  learning_rate: 0.001
  learning_rate_scheduler: KLAdaptiveRL
  learning_rate_scheduler_kwargs:
    kl_threshold: 0.01

  state_preprocessor: RunningStandardScaler
  state_preprocessor_kwargs:
    size: obs_space
    device: device
  value_preprocessor: RunningStandardScaler
  value_preprocessor_kwargs:
    size: 1
    device: device

  grad_norm_clip: 1.0
  ratio_clip: 0.2
  value_clip: 0.2
  clip_predicted_values: False

  entropy_loss_scale: 0.01
  value_loss_scale: 1.0

  kl_threshold: 0.0

  rewards_shaper: None
  time_limit_bootstrap: True

  experiment:
    directory: 'runs/go2_rough_sym'
    experiment_name: ''
    write_interval: 120

    checkpoint_interval: 5000
    store_separately: False
